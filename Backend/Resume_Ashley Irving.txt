Ashley IrvingAshleyirving124@gmail.comaarishmullam@gmail.com PROFESSIONAL SUMMARY* -Around 11+years of experience as Data Scientist with strong technical expertise, business experience, and communication skills to drive high - impact business outcomes through data-driven innovations and decisions.* Extensive experience in Text Analytics, developing different Statistical Machine Learning, Data Mining solutions to various business problems and generating data visualizations using R, Python, and Tableau.* Expertise in transforming business requirements into analytical models, designing algorithms, building models, developing data mining and reporting solutions that scale across a massive volume of Structured and unstructured data.* Experience in designing stunning visualizations using Tableau software and publishing and presenting dashboards, Storyline on web and desktop platforms.* Hands on experience in implementing LDA, Naive Bayes and skilled in Random Forests, Decision Trees, Linear and Logistic Regression, SVM, Clustering, neural networks, Principal Component Analysis and good knowledge on Recommender Systems.* Experienced in working with various Python Integrated Development Environments like Net Beans, PyCharm, PyScripter, Spyder, PyStudio, PyDev and Sublime Text.* Worked on several python packages like NumPy, matplotlib, Beautiful Soup, Pickle, PySide, SciPy, wx Python, PyTables etc.* Artificial Intelligence (ML) domains worked on include recommender system build and chat-bots. Experience in K-means Clustering, Hierarchical Clustering using Python & MATLAB.* Experience is image processing & classification using MATLAB (AlexNet).* Experience in making interactive plots & dashboards using Tableau, PowerBI and Looker with Automated BI using Python (Matplotlib, Seaborn & Altair), R(ggplot2) and in building Dash apps using JupyterDash.* Expertise in building Reinforcement Learning models such as Thompson Sampling in R and Upper Confidence Bound in Python.* Experience is crafting a AutoML model based on integration of Neural Architecture Selection, Reinforcement Learning and Evolutionary algorithms Tensorflow, KerasRL and Tensorforce.* Experience in Artificial Neural Network and Convolutional Neural Network development for data mining & statistical analysis in Python, SAS E-miner & Alteryx.* Expertise in Dimensionality Reduction techniques development & deployment such as Principal Component Analysis, Linear Discriminant Analysis, Kernel PCA and Sliced Inverse Regression in MATLAB, Python & R.* Data Mining models development using Decision Trees, Random Forest in Python, TreeNET in SPM-8 (Salford Systems) and MARS (Multivariate adaptive regression spline) in Python & Alteryx.* Static Web-page development & deployment with Machine Learning & Analytics back-end processing using Streamlit (Python) & R-Shiny.* Worked on Back-end web-app framework development using Django & Flask (Python).* Worked on geographic information systems for analyzing geographic data for landscape architecture, cartography & geo-location APIs.* Worked on integration of Machine Learning models for distance-based route optimization using geospatial & streaming public participation data.* Expertise in developing mathematical models, probabilistic models and dynamical systems models for manufacturing, healthcare, financial, consumer mapping (retail), marketing (retail & e-commerce) and research industry.* Python modules primarily worked on pandas, numpy, scikit-learn, keras, requests, BeautifulSoup, PyTorch, Matplotlib, Seaborn, Scipy, lifelines, Spacy, NLTK, Tensorflow & etc.* R packages primarily worked on ggplot2, data,table, dplyr, tidyr, Shiny, plotly, knitr, mlr3, XGBoost, Caret, Lubridate & Leaflet.* Extensively worked on Deep learning models (ANN, LSTMs and CNNs).* Convolutional Neural Network design for image classification and damage estimation for automobiles.* Recurrent Neural Network Design (LSTM) for text classification, summarization and context analysis in order to understand the collaboration & productivity metrics for various divisions and departments.* Created S3 buckets in the AWS environment to store files & archive with life-cycle policies.* Experienced in creating RDS instances to serve data through servers for responding to requests.* Expert in distilling vast amounts of data to meaningful discoveries at requisite depths. Ability to analyze most complex projects at various levels.* Worked and extracted data from various database sources like Oracle, SQL Server, DB2, and Teradata.* Well experienced in Normalization & De-Normalization techniques for optimum performance in relational and dimensional database environments.* Regularly accessing JIRA tool and other internal issue trackers for the Project development.* Skilled in System Analysis, E-R/Dimensional Data Modeling, Database Design and implementing RDBMS specific features.* The experience of working in text understanding, classification, pattern recognition, recommendation systems, targeting systems and ranking systems using Python.* Expertise in all aspects of Software Development Life cycle (SDLC) from requirement analysis, Design, Development Coding, Testing, Implementation, and Maintenance.* Hand on working experience in machine learning and statistics to draw meaningful insights from data. I am good at communication and storytelling with data.* Hands on experience on Spark MLLib utilities such as classification, regression, clustering, collaborative filtering, dimensionality reduction* Extensive experience in Text Analytics, developing different Statistical Machine Learning, Data Mining solutions to various business problems and generating data visualizations using R, Python, and Tableau.* Strong knowledge of statistical methods (regression, time series, hypothesis testing, randomized experiment), machine learning, algorithms, data structures and data infrastructure.* Proficient in statistical Modeling and Machine Learning techniques (Linear, Logistics, Decision Trees, Random Forest, SVM, K-Nearest Neighbours) in Forecasting/Predictive Analytics, Segmentation methodologies, Regression-based models, Hypothesis testing, Factor analysis/ PCA, Ensemble.* Expertise in Technical proficiency in Designing, Data Modeling Online Application, Solution Lead for Architecting Data Warehouse/Business Intelligence Applications.* Good Understanding of working on Artificial Neural Networks and Deep Learning models using Theano and TensorFlow packages using in Python.* Proficient in advising on the use of data for compiling personnel and statistical reports and preparing personnel action documents patterns within data, analyzing data and interpreting results* Strong ability to analyze sets of data for signals, patterns, ways to group data to answer questions and solve complex data puzzles* Skilled in Advanced Regression Modeling, Time Series Analysis, Statistical Testing, Correlation, Multivariate Analysis, Forecasting, Model Building, Business Intelligence tools and application of Statistical Concepts* Proficient in: Data Acquisition, Storage, Analysis, Integration, Predictive Modeling, Logistic Regression, Decision Trees, Data Mining Methods, Forecasting, Factor Analysis, Cluster Analysis, Neural Networks and other advanced statistical and econometric techniques* Adept in writing code in R and T - SQL scripts to manipulate data for data loads and extracts* Proficient in data entry, data auditing, creating data reports & monitoring data for accuracy* Ability to extract Web search and data collection, Web data mining, Extract database from website, Extract Data entry and Data processing* Strong experience with R Visualization, QlikView and Tableau to use in data analytics and graphic visualization* Extensively worked on using major statistical analysis tools such as R, SQL, SAS, and MATLAB* Strong knowledge in all phases of the SDLC (Software Development Life Cycle) from analysis, design, development, testing, implementation and maintenance with timely delivery against deadlines* Good knowledge and understanding of data mining techniques like classification, clustering, regression techniques and random forests TECHNICAL SKILLSBusiness Intelligence ToolsTableau Desktop 10.x/9.x/8.x, Tableau server, Tableau Online, Microsoft Power BI, SAP Business Objects, Crystal Reports, Power BI and SAS.Operating SystemsWindows 10/8/7/VISTA/NT/XP and LINUX/UNIX.DatabasesMS SQL Server [ ], Oracle [ ], HP Vertica, IBM UD2 DB2, Teradata, MS Access, HANA, SAP BW, AWS S3 Bucket Snowflake Schematic, Oracle, PostgreSQL, Teradata, Netezza, MS SQL Server, Mongo DB, HBase and CassandraProgramming LanguagesPython, R, JavaScript, SQL, PL/SQL, MATLAB & JavaWORK EXPERIENCEApple, Cupertino, CA Feb 2021   PresentData Science /EngineerResponsibilities:* Developed, Implemented & Maintained the Conceptual, Logical & Physical Data Models using Erwin for forwarding/Reverse Engineered Databases.* Designed algorithms to identify and extract incident alerts from a daily pool of incidents.* Reduced redundancy among incoming incidents by proposing rules to recognize patterns.* Performed exploratory data analysis like calculation of descriptive statistics, detection of outliers, assumptions testing, factor analysis, etc., in Python* Build models based on domain knowledge and customer business objectives* Extracted data from the database using Excel/Access, SQL procedures and created Python and R data frames for statistical analysis, validation, visualization, and documentation* Extensive understanding BI, analytics focusing on consumer and customer space* Innovated and leveraged machine learning, data mining and statistical techniques to create new, scalable solutions for business problems* Performed Data Profiling to assess data quality using SQL through complex internal database* Designed data profiles for processing, including running SQL, Procedural/SQL queries and using Python and R for Data Acquisition and Data Integrity which consists of Datasets Comparing and Dataset schema checks* Created stored procedures and wrote optimized queries in mySQL for efficient reporting results* Scraped Data from various study participants using the AWARE FRAMEWORK and MS GRAPH APIs using Jupyter Notebook (Python) and MySQL* Worked with Machine learning algorithms like Regressions (linear, logistic etc...), SVMs and Decision trees.* Worked on Data Subset in TDM. Data subset is the process of slicing a part of the Production Database and loading it into the Test Database.* Worked on TDM prevents bug fixes and rollbacks and overall creates a more cost-efficient software deployment process. It also lowers the organization's compliance and security risks.* Worked on Clustering and classification of data using Machine learning algorithms.* Build analytic models using a variety of techniques such as logistic regression, risk scorecards, and pattern recognition technologies.* Work with technical and development teams to deploy models. Build Model Performance Reports and Modeling Technical Documentation to support each of the models for the product line.* Performed Exploratory Data Analysis and Data Visualizations using R, and Tableau.* Analyzed data from Primary and secondary sources using statistical techniques to provide daily reports.* Estimation and Requirement Analysis of project timelines.* Analyzed data and recommended new strategies for root cause and finding the quickest way to solve big data sets.* Hands on experience in implementing Naive Bayes and skilled in Random Forests, Decision Trees, Linear and Logistic Regression, SVM, Clustering, Principal Component Analysis.* Have knowledge of A/B Testing, ANOVA, Multivariate Analysis, Association Rules and Text Analysis using R.* Performed Exploratory Data Analysis using R. Also involved in generating various graphs and charts for analyzing the data using Python Libraries.* Involved in the execution of multiple business plans and projects Ensures business needs are being met Interpret data to identify trends to go across future data sets.* Developed interactive dashboards, created various Adhoc reports for users in Tableau by connecting various data sources.* Used packages like dplyr, tidyr&ggplot2 in R Studio for data visualization.* Enhancing data collection procedures to include information that is relevant for building analytic systems.* Work on data that was a combination of unstructured and structured data from multiple sources and automate the cleaning using Python scripts.* Improve fraud prediction performance by using random forest and gradient boosting for feature selection with PythonScikit-learn.* Work on data pre-processing and cleaning the data to perform feature engineering and performed data imputation techniques for the missing values in the dataset using Python.* Implement machine learning model (logistic regression, XGBoost, SVM) with PythonScikit- learn.* Work on different data formats such as JSON, XML and applied machine learning algorithms in Python.* Processing, cleansing, and verifying the integrity of data used for analysis* Doing the ad-hoc analysis and presenting results in a clear manner* Worked with Data Governance, Data quality, data lineage, Data architect to design various models.* Designed data models and data flow diagrams using Erwin and MS Visio.* As an Architect implemented MDM hub to provide clean, consistent data for anSOA implementation.* Experience with common data science toolkits, such as R, Python, Spark, etc.* Developed and designed SQL procedures and Linux shell scripts for data export/import and for converting data.* Used Test Driven Development (TDD) for the project.* Written SQLQueries, Stored Procedures, Triggers and functions for MySQL Databases.* Coordinate with data scientists and senior technical staff to identify client's needs and document assumptions.* Established Data architecture strategy, best practices, standards, and roadmaps.* Lead the development and presentation of a data analytics data-hub prototype with the help of the other members of the emerging solutions team.* Worked with several R packages including knitr, dplyr, SparkR, Causal Infer, spacetime.* Interacted with the other departments to understand and identify data needs and requirements.Barclays- Aldi, Atherstone, UK Aug 2018   Feb 2021Data Science ConsultantResponsibilities:* Worked with a team of data scientists and data warehouse engineers, SQL & Python developers and Business Intelligence Analysts for the design of recommender system build for G Maps.* Developed & extended the open-source Python Library Tensorflow in Image Processing, object identification and labelling (Tensorflow Graphics).* Performed exploratory data analysis like calculation of descriptive statistics, detection of outliers, assumptions testing, factor analysis, etc., in Python and R,* Utilized Spark, Python, R, a broad variety of machine learning methods including classifications, regressions, dimensionality reduction based on domain knowledge and business objectives.* Innovated and leveraged machine learning, data mining and statistical techniques to create new, scalable solutions for business problems.* Effective software development processes to customize and extend the computer vision and image processing techniques to solve new problems.* Worked with Machine learning algorithms like Regressions (linear, logistic etc...), Clustering and classification, SVMs and Decision trees.* Automated applications and MySQL container deployment in Docker using Python and monitor them using Nagios.* Developed NLP models for Topic Extraction, Sentiment Analysis, context analysis.* Application of various machine learning algorithms and statistical Modeling like decision trees, text analytics, natural language processing (NLP), supervised and unsupervised, regression models, social network analysis, neural networks, deep learning, SVM, clustering to identify Volume using Scikit-learn package in python.* Worked with NLTK library to NLP data processing and finding the patterns.* Generated various automated graphing and charting tools for analyzing the data using Python Libraries.* Documented logical, physical, relational and dimensional data models. Designed the Data Marts in dimensional data modeling using star and snowflake schemas.* Recommender system build with geo-spatial data and public-participation data.* Separate & Integrated ML models build for recommender system build and priority evaluation.* Modelling and exponential smoothening for multivariate time series data.* Used Pandas, NumPy, seaborn, SciPy, Matplotlib, Scikit-learn, NLTK in Python for developing various machine learning algorithms and utilized machine learning algorithms such as linear regression, multivariate regression, naive Bayes, Random Forests, K-means, & KNN for data analysis.* Performed Source System Analysis, database design, data modeling for the warehouse layer using MLDM concepts and package layer using Dimensional modeling.* Created and implemented MDM data model for Consumer/Provider for HealthCare MDM product from Variant.* Performed Data Analysis and Data Profiling and worked on data transformations and data quality rules.* Deployed my project on GCP, connected RDS(SQL) to GCP using python.* Worked with Pandas/Numpy to analyze the data and infer from the Seaborn visualization.* Used PostgreSQL for the DB and various python libraries for data analysis and predictive modeling.* Formulated procedures for tableau with data sources and delivery systems integration of* Interacted extensively with end users on requirement gathering, analysis and documentation.* Worked extensively with Advance Analysis Actions, LODs (FIXED, INCLUDE, EXCLUDE) Calculations, Parameters, Background images, Maps.* Involved in Trouble Shooting, Performance tuning of reports and resolving issues within Tableau Desktop/Server Reports.* Worked with GCP Bigquery directly from Tableau to access cloud data warehouse and quickly perform visual analysis.* Created SSIS Packages using Pivot Transformation, Execute SQL Task, Data Flow Task, etc., to import data into the data warehouse.* Performed administrative tasks, including creation of database objects such as database, tables, and views, using SQL DCL, DDL, and DML requests.* Coding new tables, views, and modifications as well as Pl/PgSQL stored procedures, data types, triggers, constraints in PostgreSQL databases* Built and published customized interactive reports and dashboards, report scheduling using Tableau server.* Used SQL Loader to load data from the Legacy systems into Google databases using control files extensively.SNAP, Santa Monica, CA Sept 2016   July 2018Data Science ConsultantResponsibilities:* Utilized domain knowledge and application portfolio knowledge to play a key role in defining the future state of large, business technology programs.* Provided the architectural leadership in shaping strategic, business technology projects, with an emphasis on application architecture.* Participated in all phases of data mining, data collection, data cleaning, developing models, validation, and visualization and performed Gap analysis.* . Implemented a Python-based distributed random forest via Python streaming.* Designed and implemented system architecture for Microsoft Azure VM based cloud-hosted solution for client.* Worked on Azure Data Factory for data integration & transformation and loading in Azure Data Warehouse.* Ingested Data using Azure Synapse Analytics (Pipelines) & stored it in Data Lake Storage.* Used Pandas, NumPy, seaborn, SciPy, Matplotlib, Scikit-learn, NLTK in Python for developing various machine learning algorithms and utilized machine learning algorithms such as linear regression, multivariate regression, naive Bayes, Random Forests, K-means, & KNN for data analysis.* Forecasted based on exponential smoothing, ARIMA modelling, statistical algorithms and statistical analysis and transfer function models.* Conducted studies, rapid plots and using advance data mining and statistical modelling techniques to build solution that optimize the quality and performance of data.* Demonstrated experience in design and implementation of Statistical models, Predictive and descriptive models, enterprise data model, metadata solution and data life cycle management in both RDBMS, Big Data environments.* Created ecosystem models (e.g. conceptual, logical, physical, canonical) that are required for supporting services within the enterprise data architecture (conceptual data model for defining the major subject areas used, ecosystem logical model for defining standard business meaning for entities and fields, and an ecosystem canonical model for defining the standard messages and formats to be used in data integration services throughout the ecosystem).* Experience in implementing python alongside using various libraries such as matplotlib* for charts and graphs, MySQL db for database connectivity, PySide, Pandas data frame, Numpy* Wrangled data, worked on large datasets (acquired data and cleaned the data), analyzed trends by making visualizations using matplotlib using Python.* Collaborated with data engineers, wrote and optimized SQL queries to perform data extraction from SQL tables.* Gathered user requirements, analyzed and designed software solutions based on the business requirements.* Experienced in creating Prototypes, Wireframes and Mock-Up Screens to visualize Graphical User Interface (GUI). Gained insights and verified the validity of multiple datasets by mining data and executing structured queries in pandas.* Built web scrapers using restful API s to collect raw data.* Tested Complex ETL Mappings and Sessions based on business user requirements and business rules to load data from source flat files and RDBMS tables to target tables.Google, Reston, VA July 2015   July 2016Data Science ConsultantResponsibilities:* Perform Data Profiling to learn about behavior with various features of turnover before the hiring decision, when one has no on-the-job behavioral data.* Performed preliminary data analysis using descriptive statistics and handled anomalies such as removing duplicates and imputing missing values.* Applied various machine learning algorithms and statistical Modeling like decision trees, text analytics, natural language processing (NLP), supervised and unsupervised, regression models, social network analysis, neural networks, deep learning, SVM, clustering to identify Volume using Scikit-learn package in Python.* Involved in creating Hive tables, loading the data and writing Hive queries which will run internally in map reduce way.* Designed and managed API system deployment using fast HTTP server and Apple ICloud architecture* Setup database in Apple Cloud Interaction and configuring backups for S3 bucket.* Experience with XML technologies including XML, Java Script, CSS and HTML.* Expert level skills in Java Multithreading, Exception Handling, Servlets, JSP, PHP,Custom Tag Libraries, Java Script, AJAX, CSS, HTML, Struts, Spring, Hibernate, Enterprise Java Beans, JDBC, RMI, JNDI and XML related technologies.* Designed implemented and tested the Spring Domain Model for the services using Core Java.* Applied various machine learning algorithms and statistical Modeling like decision trees, text analytics, natural language processing (NLP), supervised and unsupervised, regression models, social network analysis, neural networks, deep learning, SVM, clustering to identify Volume using Scikit-learn package in Python.* Developed NLP algorithms coupled with Deep Learning for Topic Extraction, Sentiment Analysis.* Performed data cleaning and feature selection using Pandas & Numpy* Conducted a hybrid of Hierarchical and K-means Cluster Analysis and identified meaningful segments of through a discovery approach.* Built Artificial Neural Network using TensorFlow in Python to identify the customer's probability of canceling the connections. (Churn rate prediction)* Understanding the business problems and analyzing the data by using appropriate Statistical models to generate insights.* Having Knowledge on AWS Lambda, Auto scaling, Cloud Front, RDS.* Gained Knowledge on Deploying apps using AWS Cloud Formation.* Developed NLP algorithms coupled with Deep Learning for Topic Extraction, Sentiment Analysis.* Identify and assess available machine learning and statistical analysis libraries (including regressors, classifiers, statistical tests, and clustering algorithms).* Work with NLTK library to NLP data processing and finding the patterns.* Categorize comments into positive and negative clusters from different social networking sites using Sentiment Analysis and Text Analytics.* Ensure that the model has low False Positive Rate for text classification and sentiment analysis on unstructured and semi-structured data.* Addressed overfitting by implementing the algorithm regularization methods like L2 and L1.* Use Principal Component Analysis in feature engineering to analyze high dimensional data.* Create and design reports that will use gathered metrics to infer and draw logical conclusions from past and future behavior.* Perform Data Cleaning, features scaling, features engineering using pandas and NumPy packages in python.* Communicate the results with operations team for taking best decisions.* Collect data needs and requirements by Interacting with the other departments.* Build an in-depth understanding of the problem domain and available data assets with interim evaluation.* Research, design, implement, and evaluate machine learning approaches and models.* Communicate findings and obstacles to stakeholders to help drive the delivery to market.* Developed and automated the data manipulation process for above using stored procedures/views in SQL Server.* Developed the code as per the client's requirements using SQL, PL/SQL and Data Ware housing concepts.* Automated the scraping and cleaning of data from various data sources in R.* Developed Banks s loss forecasting process using relevant forecasting and regression algorithms in R.* Wrangled data, worked on large datasets (acquired data and cleaned the data), analyzed trends by making visualizations using matplotlib using Python* Collaborated with data engineers, wrote and optimized SQL queries to perform data extraction from SQL tables.Barclays- Aldi, Atherstone, UK Feb 2013   May 2015Python Developer InternResponsibilities:* Participated in the complete SDLC process and used PHP to develop website functionality.* Designed and developed the UI of the website using HTML, XHTML, AJAX, CSS, and JavaScript.* Developed entire frontend and backend modules using Python on Django Web Framework.* Designed and developed data management system using MySQL. Built application logic using Python 2.7.* Used Django APIs for database access.* Provided GUI utilizing PyQt for the end user to create, modify and view reports based on client data.* Angular.js is used to build efficient backend for client web application.* Used Python to extract information from XML files.* Expertise in Service Oriented Architecture (SOA) and its related technologies like Web Services, BPEL, WSDLs, SOAP1.1, XML, XSD, XSLT etc.* Participated in requirement gathering and worked closely with the architect in designing and modeling.* Worked on development of SQL and stored procedures on MYSQL.* Developed shopping cart for Library and integrated web services to access the payment (E-commerce)* Designed and developed a horizontally scalable APIs using Python Flask.* Designed Cassandra schema for the APIs.* Implemented monitoring and established best practices around using elastic search.* Effectively communicated with the external vendors to resolve queries.EDUCATIONThe University of Glasgow, Glasgow, UKMaster of Engineering-----END OF RESUME-----

Name: Ashley Irving
Monte Vista, CA, 95014 US
Email: ashleyirving124@gmail.com

SUMMARY
Resume Title: UploadedProfile-05ad09e0-9d11-4bb1-917b-4f47aad2a257
Security Clearance Level: None
Contact Preference: Email

Recent Position Title: Data Science /Engineer

Willing to Relocate: No
Desired Location: CA US
Work Authorization: I am authorized to work in US for any employer.

Downloaded Resume from Monster
9ketdzawbvkvhjdf